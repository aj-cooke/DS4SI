---
title: "DS4SI Final"
author: "Andrew Cooke"
date: "12/3/2021"
output: pdf_document
---

## R Markdown

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r require, include = FALSE}
# If pacman is is not installed, install pacman
if (!require("pacman")) install.packages("pacman") 
# Also install the packages inside the parentheses
pacman::p_load(pacman, dplyr, ggplot2, corrplot, RColorBrewer, pscl, 
               smotefamily, broom, MASS, gtable, gridExtra, stargazer, ROCR)
```

```{r libraries}
library("broom")
library("ggplot2")
library("MASS")
library("gtable")
library("gridExtra")
library("stargazer")
library("dplyr")
library("corrplot")
library("RColorBrewer")
library("pscl")
library("smotefamily")
library("ROCR")
```

```{r load_data}
jlm_con <- read.csv("rwm_replic_data.csv")
```

These are the original models fitted in the paper. They will be used as a 
bench mark for the subsequent models created in this document.

```{r original_models}
ind <- glm.nb(Individual ~ Mean_800 + 
                Jewish_segment + JLR_station +
                Damascus_Gate_dis + With_settlements 
              ,
              data=jlm_con)
summary(ind)

col <- glm.nb(Collective ~ Mean_800 + 
                Jewish_segment + JLR_station +
                Damascus_Gate_dis + With_settlements 
              ,
              data=jlm_con)
summary(col)
```

### Analysis 1: New Model Features

The original models use only one of Mean_800, Mean_1250, and Mean_2000 because
they are highly correlated connectivity measurements only differing by the 
change of a hyperparameter. To capture the information from the difference in
each of these while not introducing any more multicolinearity, we will add
percentage change from Mean_800 to Mean_1250 and Mean_1250 to Mean_2000.

```{r fill_nulls}
for (i in colnames(jlm_con)) {
  jlm_con[[i]][is.na(jlm_con[[i]])]<-mean(jlm_con[[i]], na.rm = TRUE)
  print(i)
}
```

```{r new_features}
jlm_con <- jlm_con %>%
  mutate(change_1250_800 = (Mean_1250 - Mean_800)/Mean_800,
         change_2000_1250 = (Mean_2000 - Mean_1250)/Mean_1250)
```

```{r correlation}
M <-cor(jlm_con)
corrplot(M, tl.col = "black", 
         tl.cex = 0.6, tl.srt = 45)
```

```{r models_with_new_features}
# Individual with new features
change_ind <- glm.nb(Individual ~ Mean_800 + 
                       Jewish_segment + JLR_station +
                       Damascus_Gate_dis + With_settlements +
                       change_1250_800 + change_2000_1250,
                     data=jlm_con)
summary(change_ind)

# Collective with new features
change_col <- glm.nb(Collective ~ Mean_800 + 
                       Jewish_segment + JLR_station +
                       Damascus_Gate_dis + With_settlements +
                       change_1250_800 + change_2000_1250,
                     data=jlm_con)
summary(change_col)
AIC(ind, change_ind)
AIC(col, change_col)
```

```{r models_compare1}
AIC(ind, change_ind)
AIC(col, change_col)
```

The new features slightly improved the individual model, but the collective
model had a higher AIC without the new features. Now we will remove 
insignificant features from the models.

```{r models_sig1}
change_ind_s <- glm.nb(Individual ~ Mean_800 + 
                       JLR_station +
                       With_settlements +
                       change_1250_800 + change_2000_1250,
                     data=jlm_con)
summary(change_ind_s)

change_col_s <- glm.nb(Collective ~ Mean_800 + 
                       Jewish_segment + 
                       Damascus_Gate_dis + With_settlements
                       ,
                     data=jlm_con)
summary(change_col_s)
```

```{r models_compare2}
AIC(ind, change_ind, change_ind_s)
AIC(col, change_col, change_col_s)
```

AIC increased for both models despite removing insignificant predictors.

## Analysis 2: Zero inflation

Some count datasets have a higher than expected proportion of 0 values. This
muddies the assumptions of traditional negative binomial and poisson regression.
When this occurs, we need to use a zero inflated model. This is essentially an
aggregation of two separate models: one is a logistic model that predicts 
whether or not there will be a zero count and then a poisson or negative 
binomial regression when there is a non-zero count. Let's see if a zero inflated
model is needed.

```{r ind_dist}
p <- ggplot(jlm_con, aes(Individual)) +
  geom_histogram(fill = "red") +
  labs(title = "Distribution of Individual Attacks")
p
```

```{r ind_dist}
p <- ggplot(jlm_con, aes(Collective)) +
  geom_histogram(fill = "red") +
  labs(title = "Distribution of Collective Attacks")
p
```

Both target variables show a glaring need for a zero inflated model. We will
also add a zero inflated poisson model for comparison.

```{r zeroinfl}
# Zero inflated models
m1 <- zeroinfl(Individual ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data = jlm_con, dist = "negbin")
summary(m1)

m2 <- zeroinfl(Collective ~ Mean_800 + #Why does collective have NA's?
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data = jlm_con, dist = "negbin")
summary(m2)

# Zero inflated poisson
m3 <- zeroinfl(Individual ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data = jlm_con, dist = "poisson")
summary(m3)

m4 <- zeroinfl(Collective ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data = jlm_con, dist = "poisson")
summary(m4)
```

```{r zinfl_comp}
AIC(ind, change_ind, change_ind_s, m1, m3)
AIC(col, change_col, change_col_s, m2, m4)
```

The individual model was further improved over the original model as it had
more zero inflation, but zero inflation did not help with the collective model.
The zero inflated negative binomial collective model did not even have any
significant variables. Let's compare the performance after we remove 
insignificant variables.

```{r zinfl_sig}
# Zero Inflated Significant Only

m1_s <- zeroinfl(Individual ~ Mean_800 + 
                 Jewish_segment + 
                 With_settlements +
                 change_1250_800 + change_2000_1250 |
                 JLR_station + change_1250_800,
               data = jlm_con, dist = "negbin")
summary(m1_s)

#m2 no significants

m3_s <- zeroinfl(Individual ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 change_1250_800 + change_2000_1250 |
                 With_settlements,
               data = jlm_con, dist = "poisson")
summary(m3_s)

m4_s <- zeroinfl(Collective ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 With_settlements +
                 change_1250_800 + change_2000_1250 |
                   With_settlements + Damascus_Gate_dis,
               data = jlm_con, dist = "poisson")
summary(m4_s)
```

```{r zinfl_sig_comp}
AIC(ind, change_ind, change_ind_s, m1, m3, m1_s, m3_s)
AIC(col, change_col, change_col_s, m2, m4, m4_s)
```

All models decreased in performance.

### Analysis 3: Logistic models

With count data problems, there is often a logistic "hurdle" model that predicts
whether the count will be above 0 or some other threshold. This fits nicely
with the research question of this paper since a robust model that can predict
whether or not there will be an attack would be more useful than a less accurate
count model that loses performance discerning between 1, 2, or 3 attacks.

```{r logit}
jlm_con <- jlm_con %>%
  mutate(Individual_ind = ifelse(Individual == 0, 0, 1),
         Collective_ind = ifelse(Collective == 0, 0, 1))

ind_log <- glm(Individual_ind ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data=jlm_con, family = "binomial")
summary(ind_log)

col_log <- glm(Collective_ind ~ Mean_800 + 
                 Jewish_segment + JLR_station +
                 Damascus_Gate_dis + With_settlements +
                 change_1250_800 + change_2000_1250,
               data=jlm_con, family = "binomial")
summary(col_log)
```

```{r logit_sig}
#Logistic Significant Only
ind_log_s <- glm(Individual_ind ~ JLR_station +
                 Damascus_Gate_dis + With_settlements,
               data=jlm_con, family = "binomial")
summary(ind_log_s)

col_log_s <- glm(Collective_ind ~ Jewish_segment +
                 Damascus_Gate_dis + With_settlements,
               data=jlm_con, family = "binomial")
summary(col_log_s)
```

```{r logit_comp}
AIC(ind, change_ind, change_ind_s, m1, m3, m1_s, m3_s, ind_log, ind_log_s)
AIC(col, change_col, change_col_s, m2, m4, m4_s, col_log, col_log_s)
```

As expected, the logistic models are much more informative than the count 
models.

### Analysis 4: Interaction Terms

Perhaps some interaction terms could be having an effect on the target variable.
these following models will see if there is any multiplicative relationship.

```{r int}
# Logistic Interaction terms
ind_log_t <- glm(Individual_ind ~ JLR_station +
                   Damascus_Gate_dis + With_settlements
                   + JLR_station:Damascus_Gate_dis
                   + JLR_station:With_settlements 
                   + Damascus_Gate_dis:With_settlements
                 ,
                 data=jlm_con, family = "binomial")
summary(ind_log_t)

col_log_t <- glm(Collective_ind ~ Jewish_segment +
                   Damascus_Gate_dis + With_settlements 
                   + Jewish_segment:Damascus_Gate_dis
                   + Jewish_segment:With_settlements 
                   + Damascus_Gate_dis:With_settlements
                 ,
                 data=jlm_con, family = "binomial")
summary(col_log_t)
```
```{r int_comp}
AIC(ind, change_ind, change_ind_s, m1, m3, m1_s, m3_s, ind_log, ind_log_s, ind_log_t)
AIC(col, change_col, change_col_s, m2, m4, m4_s, col_log, col_log_s, col_log_t)
```

No interaction terms were significantly significant. Their presence in the model
increased AIC for both individual and collective. The logistic models with only
significant variables have been the most robust models.

### Analysis 5: SMOTE

As discussed, a very high proportion of the observations had zero attacks. This
introduces the problem of a class imbalance into the logistic regression
approach. We will need to make the models more sensitive to instances where 
there is an attack. This can be accomplished by upsampling the data. Rather than
randomly upsampling the minority class with replacement, we will use Synthetic
Minority Oversampling Technique (SMOTE) to generate new synthetic samples of 
the minority class based on points between nearest neighbors.

Additionally, we will need to alter our model comparison strategy. In this case
we are mostly interested in not incorrectly classifying attacks as non-attacks
while maintaining high accuracy in preparation for future attack instances 
rather than observing the pure statistical robustness of the regression model.
Instead of AIC, we will split the data into training and testing, SMOTE the 
training set, and use a combination of accuracy, precision, recall, and F1 score
to evaluate models.

```{r split}
# SMOTE
set.seed(42)

split <- runif(nrow(jlm_con)) # random number0 to 1 for each obs
jlm_con <- cbind.data.frame(jlm_con, data.frame(split = split)) # add to df

jlm_con <- jlm_con %>%
  mutate(split_ind = ifelse(jlm_con$split > 0.2, 1, 0)) # 80% train size

train <- jlm_con[jlm_con$split_ind == 1, ]
test <- jlm_con[jlm_con$split_ind == 0, ]  

# Only want to smote based on relevant significant variables. Inclusion of
# others will throw off the SMOTE nearest neighbors algorithm

ind_train <- train[ , c('Individual_ind', 'JLR_station', 'Damascus_Gate_dis', 
                        'With_settlements')]
col_train <- train[ , c('Collective_ind', 'Jewish_segment', 'Damascus_Gate_dis', 
                        'With_settlements')]
```

```{r base}
# Train base models on training sets with significant features from prev model
ind_base <- glm(Individual_ind ~ JLR_station +
               Damascus_Gate_dis + With_settlements,
             data=ind_train, family = "binomial")
summary(ind_base)

col_base <- glm(Collective_ind ~ Jewish_segment +
                  Damascus_Gate_dis + With_settlements,
                data=col_train, family = "binomial")
summary(col_base)
```

```{r smote_df}
# dup_size in smote function is desired minority class size / actual minority size

IND_DUP_SIZE = 0.4 / (table(train$Individual_ind)[2] / (table(train$Individual_ind)[2] 
                                                   + table(train$Individual_ind)[1]))
COL_DUP_SIZE = 0.4 / (table(train$Collective_ind)[2] / (table(train$Collective_ind)[2] 
                                                              + table(train$Collective_ind)[1]))

# create smoted training sets using smote function
ind_smote_df <- SMOTE(ind_train, ind_train$Individual_ind, K = 3, dup_size = IND_DUP_SIZE)
ind_smote_df <- ind_smote_df$data

col_smote_df <- SMOTE(col_train, col_train$Collective_ind, K = 3, dup_size = COL_DUP_SIZE)
col_smote_df <- col_smote_df$data
```

```{r smote_models}
ind_smote <- glm(Individual_ind ~ JLR_station +
                  Damascus_Gate_dis + With_settlements,
                data=ind_smote_df, family = "binomial")
summary(ind_smote)

col_smote <- glm(Collective_ind ~ Jewish_segment +
                  Damascus_Gate_dis + With_settlements,
                data=col_smote_df, family = "binomial")
summary(col_smote)
```

```{r predict}
# for each model, add predict column to the test set
test <- test %>%
  mutate(ind_base_prob = predict(ind_base, newdata = test, type = "response"),
         col_base_prob = predict(col_base, newdata = test, type = "response"),
         ind_smote_prob = predict(ind_smote, newdata = test, type = "response"),
         col_smote_prob = predict(ind_smote, newdata = test, type = "response"),
         ind_base_pred = if_else(ind_base_prob >= 0.5, 1, 0),
         col_base_pred = if_else(col_base_prob >= 0.5, 1, 0),
         ind_smote_pred = if_else(ind_smote_prob >= 0.5, 1, 0),
         col_smote_pred = if_else(col_smote_prob >= 0.5, 1, 0))
```

```{r confusion}
# Based on confusion matrix find accuracy, precision, recall, and f1 for models
ind_base_confusion = as.matrix(table(Actual_Values = test$Individual_ind, Predicted_Values = test$ind_base_pred)) 
print(ind_base_confusion)
IND_BASE_ACC = (ind_base_confusion[1,1] + ind_base_confusion[2,2]) / (nrow(test))
IND_BASE_PREC = (ind_base_confusion[2,2])/(ind_base_confusion[2,2]+ind_base_confusion[1,2])
IND_BASE_RECALL = (ind_base_confusion[2,2])/(ind_base_confusion[2,2]+ind_base_confusion[2,1])
IND_BASE_F1 = 2*((IND_BASE_PREC * IND_BASE_RECALL) / (IND_BASE_PREC+IND_BASE_RECALL))

col_base_confusion = as.matrix(table(Actual_Values = test$Collective_ind, Predicted_Values = test$col_base_pred)) 
print(col_base_confusion)
COL_BASE_ACC = (col_base_confusion[1,1] + col_base_confusion[2,2]) / (nrow(test))
COL_BASE_PREC = (col_base_confusion[2,2])/(col_base_confusion[2,2]+col_base_confusion[1,2])
COL_BASE_RECALL = (col_base_confusion[2,2])/(col_base_confusion[2,2]+col_base_confusion[2,1])
COL_BASE_F1 = 2*((COL_BASE_PREC * COL_BASE_RECALL) / (COL_BASE_PREC+COL_BASE_RECALL))

ind_smote_confusion = as.matrix(table(Actual_Values = test$Individual_ind, Predicted_Values = test$ind_smote_pred)) 
print(ind_smote_confusion)
IND_SMOTE_ACC = (ind_smote_confusion[1,1] + ind_smote_confusion[2,2]) / (nrow(test))
IND_SMOTE_PREC = (ind_smote_confusion[2,2])/(ind_smote_confusion[2,2]+ind_smote_confusion[1,2])
IND_SMOTE_RECALL = (ind_smote_confusion[2,2])/(ind_smote_confusion[2,2]+ind_smote_confusion[2,1])
IND_SMOTE_F1 = 2*((IND_SMOTE_PREC * IND_SMOTE_RECALL) / (IND_SMOTE_PREC+IND_SMOTE_RECALL))

col_smote_confusion = as.matrix(table(Actual_Values = test$Collective_ind, Predicted_Values = test$col_smote_pred)) 
print(col_smote_confusion)
COL_SMOTE_ACC = (col_smote_confusion[1,1] + col_smote_confusion[2,2]) / (nrow(test))
COL_SMOTE_PREC = (col_smote_confusion[2,2])/(col_smote_confusion[2,2]+col_smote_confusion[1,2])
COL_SMOTE_RECALL = (col_smote_confusion[2,2])/(col_smote_confusion[2,2]+col_smote_confusion[2,1])
COL_SMOTE_F1 = 2*((COL_SMOTE_PREC * COL_SMOTE_RECALL) / (COL_SMOTE_PREC+COL_SMOTE_RECALL))
```
For the non-smoted individual model, you would be nearly as effective just
predicting no attacks as the model only predicted one attack. However for 
collective, the smoted model predicted more positives, but they were both false
positives indicating the SMOTE training did not imporve the model


```{r confusion}
# Nicely formatted table with metrics
performance <- data.frame(model = c('ind_base', 'col_base', 'ind_smote', 'col_smote'),
                          accuracy = c(IND_BASE_ACC, COL_BASE_ACC, IND_SMOTE_ACC, COL_SMOTE_ACC),
                          precision = c(IND_BASE_PREC, COL_BASE_PREC, IND_SMOTE_PREC, COL_SMOTE_PREC),
                          recall = c(IND_BASE_RECALL, COL_BASE_RECALL, IND_SMOTE_RECALL, COL_SMOTE_RECALL),
                          f1 = c(IND_BASE_F1, COL_BASE_F1, IND_SMOTE_F1, COL_SMOTE_F1))
print(performance)
```
For individual, the smoted model had the same accuracy, but higher recall and F1
indicating it is more useful. For collective, the most effective model remains
the logistic regression with only the significant attributes including no 
interaction terms. Sometimes simple is best.


```{r roc}
predi <- prediction(test$ind_base_pred, test$Individual_ind)
perfi <- performance(predi,"tpr","fpr")
predis <- prediction(test$ind_smote_pred, test$Individual_ind)
perfis <- performance(predis,"tpr","fpr")
plot(perfi, col = "blue")
plot(perfis, add = TRUE, col = "red")
ibase_label <- round(performance(predi, measure = "auc")@y.values[[1]], 2)
ibase_label <- paste("Individual Base - AUC = ", ibase_label)
ismote_label <- round(performance(predis, measure = "auc")@y.values[[1]], 2)
ismote_label <- paste("Individual SMOTE - AUC = ", ismote_label)
legend(0.5,0.3,legend=c(ibase_label, ismote_label), 
       fill = c("blue","red")
)
title("ROC Curve, Individual Base vs. Smoted Logistic Regression")
```

```{r roc}
predc <- prediction(test$col_base_pred, test$Collective_ind)
perfc <- performance(predc,"tpr","fpr")
predcs <- prediction(test$col_smote_pred, test$Collective_ind)
perfcs <- performance(predcs,"tpr","fpr")
plot(perfc, col = "blue")
plot(perfcs, add = TRUE, col = "red")
cbase_label <- round(performance(predc, measure = "auc")@y.values[[1]], 2)
cbase_label <- paste("Collective Base - AUC = ", cbase_label)
csmote_label <- round(performance(predcs, measure = "auc")@y.values[[1]], 2)
csmote_label <- paste("Collective SMOTE - AUC = ", csmote_label)
legend(0.5,0.3,legend=c(cbase_label, csmote_label), 
       fill = c("blue","red")
)
title("ROC Curve, Collective Base vs. Smoted Logistic Regression")
```


